{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.text import text_to_word_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import FreqDist\n",
    "import os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data\n",
    "source = 'input.txt'\n",
    "input_file = open(source, 'r')\n",
    "data = input_file.read()\n",
    "input_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = data.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an array of every sentence\n",
    "#convert \"how are you\" => [\"how\",\"are\",\"you\"]\n",
    "text_sequence = [text_to_word_sequence(y, lower=True, split=\" \") for y in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['what', 'is', '4', '5g', 'it', 'the', 'fastest', 'mobile', 'broadband', 'connection', 'in', 'lebanon', 'with', 'a', 'speed', 'up', 'to', '260', 'mbps', 'where', 'can', 'i', 'add', 'service', 'you', 'activate', 'high', 'internet', 'on', 'your', 'existing', 'touch', 'line', 'or', 'by', 'issuing', 'separate', 'data', 'only', 'sim', 'card', 'whether', 'holding', 'not', 'are', 'needed', 'settings', 'make', 'sure', 'device', 'lte', '4g', 'enabled', 'switching', 'network', 'mode', 'under', '2g', '3g', 'gsm', 'wcdma', 'auto', 'also', 'that', 'access', 'point', 'name', 'apn', \"'touch'\", 'for', 'detailed', 'instructions', 'visit', 'devices', 'section', 'my', 'unused', 'mbs', 'carried', 'over', 'next', 'month', \"there's\", 'no', 'accumulation', 'of', 'from', 'one', 'another', 'how', 'do', 'know', 'if', 'am', \"you're\", 'connected', 'phone', 'screen', 'will', 'display', 'bar', 'does', 'video', 'call', 'consume', 'at', 'all', 'charged', 'minute', 'rate', 'an', 'international', 'yes', 'other', 'operator', 'supports', 'this', 'feature', 'much', 'cost', '5', 'excluding', 'vat', 'postpaid', 'customers', 'and', '19', 'prepaid', 'including', 'worth', 'credit', 'lose', 'any', 'remaining', 'credits', 'accumulate', 'every', 'time', 'recharge', 'which', 'vouchers', 'be', 'used', 'top', 'use', 'voucher', \"it's\", 'magic', 'start', 'smart', 'super'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a vocab list with frequency of every word\n",
    "#set the longest word allowed to be 19 => (0 based)\n",
    "vocab = FreqDist(np.hstack(text_sequence)).keys()\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ZERO',\n",
       " 'what',\n",
       " 'is',\n",
       " '4',\n",
       " '5g',\n",
       " 'it',\n",
       " 'the',\n",
       " 'fastest',\n",
       " 'mobile',\n",
       " 'broadband',\n",
       " 'connection',\n",
       " 'in',\n",
       " 'lebanon',\n",
       " 'with',\n",
       " 'a',\n",
       " 'speed',\n",
       " 'up',\n",
       " 'to',\n",
       " '260',\n",
       " 'mbps',\n",
       " 'where',\n",
       " 'can',\n",
       " 'i',\n",
       " 'add',\n",
       " 'service',\n",
       " 'you',\n",
       " 'activate',\n",
       " 'high',\n",
       " 'internet',\n",
       " 'on',\n",
       " 'your',\n",
       " 'existing',\n",
       " 'touch',\n",
       " 'line',\n",
       " 'or',\n",
       " 'by',\n",
       " 'issuing',\n",
       " 'separate',\n",
       " 'data',\n",
       " 'only',\n",
       " 'sim',\n",
       " 'card',\n",
       " 'whether',\n",
       " 'holding',\n",
       " 'not',\n",
       " 'are',\n",
       " 'needed',\n",
       " 'settings',\n",
       " 'make',\n",
       " 'sure',\n",
       " 'device',\n",
       " 'lte',\n",
       " '4g',\n",
       " 'enabled',\n",
       " 'switching',\n",
       " 'network',\n",
       " 'mode',\n",
       " 'under',\n",
       " '2g',\n",
       " '3g',\n",
       " 'gsm',\n",
       " 'wcdma',\n",
       " 'auto',\n",
       " 'also',\n",
       " 'that',\n",
       " 'access',\n",
       " 'point',\n",
       " 'name',\n",
       " 'apn',\n",
       " \"'touch'\",\n",
       " 'for',\n",
       " 'detailed',\n",
       " 'instructions',\n",
       " 'visit',\n",
       " 'devices',\n",
       " 'section',\n",
       " 'my',\n",
       " 'unused',\n",
       " 'mbs',\n",
       " 'carried',\n",
       " 'over',\n",
       " 'next',\n",
       " 'month',\n",
       " \"there's\",\n",
       " 'no',\n",
       " 'accumulation',\n",
       " 'of',\n",
       " 'from',\n",
       " 'one',\n",
       " 'another',\n",
       " 'how',\n",
       " 'do',\n",
       " 'know',\n",
       " 'if',\n",
       " 'am',\n",
       " \"you're\",\n",
       " 'connected',\n",
       " 'phone',\n",
       " 'screen',\n",
       " 'will',\n",
       " 'display',\n",
       " 'bar',\n",
       " 'does',\n",
       " 'video',\n",
       " 'call',\n",
       " 'consume',\n",
       " 'at',\n",
       " 'all',\n",
       " 'charged',\n",
       " 'minute',\n",
       " 'rate',\n",
       " 'an',\n",
       " 'international',\n",
       " 'yes',\n",
       " 'other',\n",
       " 'operator',\n",
       " 'supports',\n",
       " 'this',\n",
       " 'feature',\n",
       " 'much',\n",
       " 'cost',\n",
       " '5',\n",
       " 'excluding',\n",
       " 'vat',\n",
       " 'postpaid',\n",
       " 'customers',\n",
       " 'and',\n",
       " '19',\n",
       " 'prepaid',\n",
       " 'including',\n",
       " 'worth',\n",
       " 'credit',\n",
       " 'lose',\n",
       " 'any',\n",
       " 'remaining',\n",
       " 'credits',\n",
       " 'accumulate',\n",
       " 'every',\n",
       " 'time',\n",
       " 'recharge',\n",
       " 'which',\n",
       " 'vouchers',\n",
       " 'be',\n",
       " 'used',\n",
       " 'top',\n",
       " 'use',\n",
       " 'voucher',\n",
       " \"it's\",\n",
       " 'magic',\n",
       " 'start',\n",
       " 'smart',\n",
       " 'super',\n",
       " 'UNK']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating an array of words from the vocabulary set, we will use this array as index-to-word dictionary\n",
    "index_to_word = [word for word in vocab]\n",
    "# Adding the word \"ZERO\" to the beginning of the array\n",
    "index_to_word.insert(0, 'ZERO')\n",
    "# Adding the word 'UNK' to the end of the array (stands for UNKNOWN words)\n",
    "index_to_word.append('UNK')\n",
    "index_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"'touch'\": 69,\n",
       " '19': 127,\n",
       " '260': 18,\n",
       " '2g': 58,\n",
       " '3g': 59,\n",
       " '4': 3,\n",
       " '4g': 52,\n",
       " '5': 121,\n",
       " '5g': 4,\n",
       " 'UNK': 152,\n",
       " 'ZERO': 0,\n",
       " 'a': 14,\n",
       " 'access': 65,\n",
       " 'accumulate': 136,\n",
       " 'accumulation': 85,\n",
       " 'activate': 26,\n",
       " 'add': 23,\n",
       " 'all': 107,\n",
       " 'also': 63,\n",
       " 'am': 94,\n",
       " 'an': 111,\n",
       " 'and': 126,\n",
       " 'another': 89,\n",
       " 'any': 133,\n",
       " 'apn': 68,\n",
       " 'are': 45,\n",
       " 'at': 106,\n",
       " 'auto': 62,\n",
       " 'bar': 101,\n",
       " 'be': 142,\n",
       " 'broadband': 9,\n",
       " 'by': 35,\n",
       " 'call': 104,\n",
       " 'can': 21,\n",
       " 'card': 41,\n",
       " 'carried': 79,\n",
       " 'charged': 108,\n",
       " 'connected': 96,\n",
       " 'connection': 10,\n",
       " 'consume': 105,\n",
       " 'cost': 120,\n",
       " 'credit': 131,\n",
       " 'credits': 135,\n",
       " 'customers': 125,\n",
       " 'data': 38,\n",
       " 'detailed': 71,\n",
       " 'device': 50,\n",
       " 'devices': 74,\n",
       " 'display': 100,\n",
       " 'do': 91,\n",
       " 'does': 102,\n",
       " 'enabled': 53,\n",
       " 'every': 137,\n",
       " 'excluding': 122,\n",
       " 'existing': 31,\n",
       " 'fastest': 7,\n",
       " 'feature': 118,\n",
       " 'for': 70,\n",
       " 'from': 87,\n",
       " 'gsm': 60,\n",
       " 'high': 27,\n",
       " 'holding': 43,\n",
       " 'how': 90,\n",
       " 'i': 22,\n",
       " 'if': 93,\n",
       " 'in': 11,\n",
       " 'including': 129,\n",
       " 'instructions': 72,\n",
       " 'international': 112,\n",
       " 'internet': 28,\n",
       " 'is': 2,\n",
       " 'issuing': 36,\n",
       " 'it': 5,\n",
       " \"it's\": 147,\n",
       " 'know': 92,\n",
       " 'lebanon': 12,\n",
       " 'line': 33,\n",
       " 'lose': 132,\n",
       " 'lte': 51,\n",
       " 'magic': 148,\n",
       " 'make': 48,\n",
       " 'mbps': 19,\n",
       " 'mbs': 78,\n",
       " 'minute': 109,\n",
       " 'mobile': 8,\n",
       " 'mode': 56,\n",
       " 'month': 82,\n",
       " 'much': 119,\n",
       " 'my': 76,\n",
       " 'name': 67,\n",
       " 'needed': 46,\n",
       " 'network': 55,\n",
       " 'next': 81,\n",
       " 'no': 84,\n",
       " 'not': 44,\n",
       " 'of': 86,\n",
       " 'on': 29,\n",
       " 'one': 88,\n",
       " 'only': 39,\n",
       " 'operator': 115,\n",
       " 'or': 34,\n",
       " 'other': 114,\n",
       " 'over': 80,\n",
       " 'phone': 97,\n",
       " 'point': 66,\n",
       " 'postpaid': 124,\n",
       " 'prepaid': 128,\n",
       " 'rate': 110,\n",
       " 'recharge': 139,\n",
       " 'remaining': 134,\n",
       " 'screen': 98,\n",
       " 'section': 75,\n",
       " 'separate': 37,\n",
       " 'service': 24,\n",
       " 'settings': 47,\n",
       " 'sim': 40,\n",
       " 'smart': 150,\n",
       " 'speed': 15,\n",
       " 'start': 149,\n",
       " 'super': 151,\n",
       " 'supports': 116,\n",
       " 'sure': 49,\n",
       " 'switching': 54,\n",
       " 'that': 64,\n",
       " 'the': 6,\n",
       " \"there's\": 83,\n",
       " 'this': 117,\n",
       " 'time': 138,\n",
       " 'to': 17,\n",
       " 'top': 144,\n",
       " 'touch': 32,\n",
       " 'under': 57,\n",
       " 'unused': 77,\n",
       " 'up': 16,\n",
       " 'use': 145,\n",
       " 'used': 143,\n",
       " 'vat': 123,\n",
       " 'video': 103,\n",
       " 'visit': 73,\n",
       " 'voucher': 146,\n",
       " 'vouchers': 141,\n",
       " 'wcdma': 61,\n",
       " 'what': 1,\n",
       " 'where': 20,\n",
       " 'whether': 42,\n",
       " 'which': 140,\n",
       " 'will': 99,\n",
       " 'with': 13,\n",
       " 'worth': 130,\n",
       " 'yes': 113,\n",
       " 'you': 25,\n",
       " \"you're\": 95,\n",
       " 'your': 30}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the word-to-index dictionary from the array created above\n",
    "word_to_index = {word:ix for ix, word in enumerate(index_to_word)}\n",
    "word_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3, 4],\n",
       " [5, 2, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
       " [20, 21, 22, 23, 6, 3, 4, 24],\n",
       " [25,\n",
       "  21,\n",
       "  26,\n",
       "  6,\n",
       "  27,\n",
       "  15,\n",
       "  28,\n",
       "  24,\n",
       "  3,\n",
       "  4,\n",
       "  29,\n",
       "  30,\n",
       "  31,\n",
       "  32,\n",
       "  33,\n",
       "  34,\n",
       "  35,\n",
       "  36,\n",
       "  14,\n",
       "  37,\n",
       "  38,\n",
       "  39,\n",
       "  40,\n",
       "  41,\n",
       "  42,\n",
       "  43,\n",
       "  14,\n",
       "  32,\n",
       "  33,\n",
       "  34,\n",
       "  44],\n",
       " [1, 45, 6, 46, 47],\n",
       " [48,\n",
       "  49,\n",
       "  30,\n",
       "  50,\n",
       "  2,\n",
       "  51,\n",
       "  52,\n",
       "  53,\n",
       "  35,\n",
       "  54,\n",
       "  6,\n",
       "  55,\n",
       "  56,\n",
       "  57,\n",
       "  55,\n",
       "  47,\n",
       "  17,\n",
       "  58,\n",
       "  59,\n",
       "  52,\n",
       "  34,\n",
       "  60,\n",
       "  61,\n",
       "  51,\n",
       "  62,\n",
       "  63,\n",
       "  48,\n",
       "  49,\n",
       "  64,\n",
       "  6,\n",
       "  65,\n",
       "  66,\n",
       "  67,\n",
       "  68,\n",
       "  2,\n",
       "  69,\n",
       "  70,\n",
       "  71,\n",
       "  72,\n",
       "  73,\n",
       "  6,\n",
       "  74,\n",
       "  75],\n",
       " [45, 76, 77, 78, 79, 80, 17, 6, 81, 82],\n",
       " [83, 84, 85, 86, 78, 13, 6, 3, 4, 24, 87, 88, 82, 17, 89],\n",
       " [90, 91, 22, 92, 93, 22, 94, 29, 3, 4, 55],\n",
       " [93,\n",
       "  95,\n",
       "  96,\n",
       "  17,\n",
       "  32,\n",
       "  3,\n",
       "  4,\n",
       "  55,\n",
       "  6,\n",
       "  97,\n",
       "  98,\n",
       "  99,\n",
       "  100,\n",
       "  52,\n",
       "  34,\n",
       "  51,\n",
       "  81,\n",
       "  17,\n",
       "  6,\n",
       "  55,\n",
       "  101],\n",
       " [102, 103, 104, 105, 87, 76, 78],\n",
       " [44, 106, 107, 95, 39, 108, 70, 6, 103, 104, 109, 110],\n",
       " [21, 22, 48, 111, 112, 103, 104],\n",
       " [113, 93, 6, 114, 115, 116, 117, 118],\n",
       " [90, 119, 102, 14, 38, 39, 40, 41, 120],\n",
       " [6,\n",
       "  120,\n",
       "  86,\n",
       "  14,\n",
       "  38,\n",
       "  39,\n",
       "  40,\n",
       "  41,\n",
       "  2,\n",
       "  121,\n",
       "  122,\n",
       "  123,\n",
       "  70,\n",
       "  124,\n",
       "  125,\n",
       "  126,\n",
       "  127,\n",
       "  122,\n",
       "  123,\n",
       "  70,\n",
       "  128,\n",
       "  125,\n",
       "  129,\n",
       "  127,\n",
       "  130,\n",
       "  86,\n",
       "  131],\n",
       " [91, 22, 132, 133, 134, 135, 29, 76, 38, 39, 40, 41],\n",
       " [44, 106, 107, 135, 99, 136, 137, 138, 25, 139],\n",
       " [140, 139, 141, 21, 142, 143, 17, 144, 16, 76, 128, 38, 39, 40, 41],\n",
       " [25,\n",
       "  21,\n",
       "  145,\n",
       "  133,\n",
       "  139,\n",
       "  146,\n",
       "  17,\n",
       "  144,\n",
       "  16,\n",
       "  30,\n",
       "  38,\n",
       "  39,\n",
       "  40,\n",
       "  41,\n",
       "  42,\n",
       "  147,\n",
       "  148,\n",
       "  149,\n",
       "  150,\n",
       "  34,\n",
       "  151]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting each word to its index value\n",
    "for i, sentence in enumerate(text_sequence):\n",
    "    for j, word in enumerate(sentence):\n",
    "        if word in word_to_index:\n",
    "            text_sequence[i][j] = word_to_index[word]\n",
    "        else:\n",
    "            text_sequence[i][j] = word_to_index['UNK']\n",
    "            \n",
    "text_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the length of the longest sentence\n",
    "longest_text_length = max([len(sentence) for sentence in text_sequence])\n",
    "#pad the sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "# add padding=\"post\" to add the pads after the content of the array, instead of at first\n",
    "padded_text_sequence = pad_sequences(text_sequence, padding='post', maxlen=longest_text_length, dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modeling time\n",
    "#import necessary modules\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, TimeDistributed, Dense, RepeatVector, recurrent, Embedding\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.optimizers import Adam, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(vocab_len, max_len, hidden_size, num_layers):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Creating encoder network\n",
    "    model.add(Embedding(vocab_len, 1000, input_length=max_len, mask_zero=True))\n",
    "    model.add(LSTM(hidden_size))\n",
    "    model.add(RepeatVector(max_len))\n",
    "\n",
    "    # Creating decoder network\n",
    "    for _ in range(num_layers):\n",
    "        model.add(LSTM(hidden_size, return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(vocab_len)))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "            optimizer='rmsprop',\n",
    "            metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 1000\n",
    "layer_num = 3\n",
    "input_max_len = max([len(sentence) for sentence in padded_text_sequence])\n",
    "vocab_len = len(vocab)+2\n",
    "model = create_model(vocab_len, input_max_len, hidden_dim, layer_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_data(word_sentences, max_len, word_to_index):\n",
    "    # Vectorizing each element in each sequence\n",
    "    sequences = np.zeros((len(word_sentences), max_len, len(word_to_index)))\n",
    "    for i, sentence in enumerate(word_sentences):\n",
    "        for j, word in enumerate(sentence):\n",
    "            sequences[i, j, word] = 1.\n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "10/10 [==============================] - 7s - loss: 5.0300 - acc: 0.0000e+00\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 3s - loss: 4.4146 - acc: 0.5256\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 3s - loss: 7.2679 - acc: 0.5256\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 3s - loss: 3.8501 - acc: 0.5302\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 3s - loss: 6.3842 - acc: 0.0023\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 3s - loss: 4.3994 - acc: 0.5256\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 3s - loss: 5.2262 - acc: 0.0093\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 3s - loss: 3.0787 - acc: 0.5256\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 3s - loss: 3.1495 - acc: 0.5256\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 3s - loss: 4.2251 - acc: 0.4628\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 3s - loss: 2.8745 - acc: 0.5256\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 3s - loss: 2.8661 - acc: 0.5256\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 3s - loss: 2.7776 - acc: 0.5256\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 3s - loss: 7.8201 - acc: 0.2209\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 3s - loss: 6.3367 - acc: 0.2907\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 3s - loss: 3.4867 - acc: 0.3140\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 3s - loss: 2.7476 - acc: 0.5256\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 3s - loss: 3.0075 - acc: 0.3163\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 3s - loss: 2.9115 - acc: 0.5279\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 3s - loss: 3.2630 - acc: 0.5256\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1212fae48>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions = padded_text_sequence[0:][::2]\n",
    "answers = padded_text_sequence[1:][::2]\n",
    "answer_sequences = process_data(answers, len(answers[0]), word_to_index)\n",
    "\n",
    "model.fit(questions,\n",
    "    answer_sequences, \n",
    "    batch_size=len(questions),\n",
    "    epochs=20, \n",
    "    verbose=1, \n",
    "    callbacks=None, \n",
    "    validation_split=0.0, \n",
    "    validation_data=None, \n",
    "    shuffle=True, \n",
    "    class_weight=None, \n",
    "    sample_weight=None, \n",
    "    initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('checkpoint_epoch_{}.hdf5'.format(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what', 'are', 'the', 'needed', 'settings']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input = text_to_word_sequence(\"What are the needed settings\", lower=True, split=\" \")\n",
    "test_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j, word in enumerate(test_input):\n",
    "        if word in word_to_index:\n",
    "            test_input[j] = word_to_index[word]\n",
    "        else:\n",
    "            test_input[j] = word_to_index['UNK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1, 45,  6, 46, 47,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0]], dtype=int32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = pad_sequences([test_input], padding='post', maxlen=longest_text_length, dtype='int32')\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[26 26 50  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "activate activate device\n"
     ]
    }
   ],
   "source": [
    "def find_checkpoint_file(folder):\n",
    "    checkpoint_file = [f for f in os.listdir(folder) if 'checkpoint' in f]\n",
    "    if len(checkpoint_file) == 0:\n",
    "        return []\n",
    "    modified_time = [os.path.getmtime(f) for f in checkpoint_file]\n",
    "    return checkpoint_file[np.argmax(modified_time)]\n",
    "\n",
    "saved_weights = find_checkpoint_file('.')\n",
    "model.load_weights(saved_weights)\n",
    "\n",
    "predictions = np.argmax(model.predict(X_test), axis=2)\n",
    "sequences = []\n",
    "print(predictions)\n",
    "for prediction in predictions:\n",
    "    sequence = ' '.join([index_to_word[index] for index in prediction if index > 0])\n",
    "    print(sequence)\n",
    "    sequences.append(sequence)\n",
    "\n",
    "#np.savetxt('test_result', sequences, fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
